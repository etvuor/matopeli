{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48574939",
   "metadata": {},
   "source": [
    "This is the template for the image recognition exercise. <Br>\n",
    "Some **general instructions**, read these carefully:\n",
    " - The final assignment is returned as a clear and understandable *report*\n",
    "    - define shortly the concepts and explain the phases you use\n",
    "    - use the Markdown feature of the notebook for larger explanations\n",
    " - return your output as a *working* Jupyter notebook\n",
    " - name your file as Exercise_MLPR2023_Partx_uuid.jpynb\n",
    "    - use the uuid code determined below\n",
    "    - use this same code for each part of the assignment\n",
    " - write easily readable code with comments     \n",
    "     - if you exploit code from web, provide a reference\n",
    " - it is ok to discuss with a friend about the assignment. But it is not ok to copy someone's work. Everyone should submit their own implementation\n",
    "     - in case of identical submissions, both submissions are failed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfbc2b3",
   "metadata": {},
   "source": [
    "**Deadlines:**\n",
    "- Part 1: Mon 6.2 at 23:59**\n",
    "- Part 2: Mon 20.2 at 23:59**\n",
    "- Part 3: Mon 6.3 at 23:59**\n",
    "\n",
    "**No extensions for the deadlines** <br>\n",
    "- after each deadline, example results are given, and it is not possible to submit anymore\n",
    "\n",
    "**If you encounter problems, Google first and if you canâ€™t find an answer, ask for help**\n",
    "- Moodle area for questions\n",
    "- pekavir@utu.fi\n",
    "- teacher available for questions on Mondays 30.1, 13.2 (after lecture) and Thursday 2.3 (at lecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea03f4ab",
   "metadata": {},
   "source": [
    "**Grading**\n",
    "\n",
    "The exercise covers a part of the grading in this course. The course exam has 5 questions, 6 points of each. Exercise gives 6 points, i.e. the total score is 36 points.\n",
    "\n",
    "From the template below, you can see how many exercise points can be acquired from each task. Exam points are given according to the table below: <br>\n",
    "<br>\n",
    "7 exercise points: 1 exam point <br>\n",
    "8 exercise points: 2 exam points <br>\n",
    "9 exercise points: 3 exam points <br>\n",
    "10 exercise points: 4 exam points <br>\n",
    "11 exercise points: 5 exam points <br>\n",
    "12 exercise points: 6 exam points <br>\n",
    "<br>\n",
    "To pass the exercise, you need at least 7 exercise points, and at least 1 exercise point from each Part.\n",
    "    \n",
    "Each student will grade one submission from a peer and their own submission. After each Part deadline, example results are given. Study them carefully and perform the grading according to the given instructions. Mean value from the peer grading and self-grading is used for the final points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20913a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The id code is: 4d05cbe3-bb52-11ed-876e-34f64b772b02\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "# Run this cell only once and save the code. Use the same id code for each Part.\n",
    "# Printing random id using uuid1()\n",
    "print (\"The id code is: \",end=\"\")\n",
    "print (uuid.uuid1())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce21d52",
   "metadata": {},
   "source": [
    "# Introduction (1 p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ca8979",
   "metadata": {},
   "source": [
    "Write an introductory chapter for your report\n",
    "<br>\n",
    "- Explain what is the purpose of this task?\n",
    "- Describe, what kind of data were used? Where did it originate? Give correct reference.\n",
    "- Which methods did you use?\n",
    "- Describe shortly the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d8f85d",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The purpose of this task was to analyze a dataset in order to find insights that could help with decision-making. In other words the task was to extract meaningful information from the dataset and try to present it in a clear and understandable manner.\n",
    "\n",
    "The data used in this task was obtained from https://www.muratkoklu.com/datasets/vtdhnd09.php, which consists of 75 000 thousands pictures of 5 different types of rice, in our task we only used 300 pictures of 3 different types of rice(100pictures/ricetype).\n",
    "\n",
    "Multiple methods were used including data exploration, visualization, and statistical analysis.\n",
    "\n",
    "Overall the result show how well different models are able to predict the datapoints to the correct ricetypes and what are the most important features of the ricetypes in order for use to predict this information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d49e7d2",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec0706",
   "metadata": {},
   "source": [
    "Data exploration and model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d85ec88",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d973b1d7",
   "metadata": {},
   "source": [
    "## Performance estimation (2 p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3929defa",
   "metadata": {},
   "source": [
    "Use the previously gathered data (again, use the standardized features). <br>\n",
    "Estimate the performance of each model using nested cross validation. Use 10-fold cross validation for outer and <br>\n",
    "5-fold repeated cross validation with 3 repetitions for inner loop.  <br> \n",
    "Select the best model in the inner loop using the hyperparameter combinations and ranges defined in the Part 2. <br>\n",
    "For each model, calculate the accuracy and the confusion matrix. <br> \n",
    "Which hyperparameter/hyperparameter combination is most often chosen as the best one for each classifier? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f896a1",
   "metadata": {},
   "source": [
    "## Discussion (2 p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c6e2e9",
   "metadata": {},
   "source": [
    "Discuss you results\n",
    "\n",
    "- Which model performs the best? Why?\n",
    "- Ponder the limitations and generalization of the models. How well will the classifiers perform for data outside this data set?\n",
    "- Compare your results with the original article. Are they comparable?\n",
    "- Ponder applications for these type of models (classifying rice or other plant species), who could benefit from them? Ponder also what would be interesting to study more on this area?\n",
    "- What did you learn? What was difficult? Could you improve your own working process in some way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c839eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing all the packages needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score, RepeatedKFold, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2961096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is from part2 I hadn't saved the standardized data that's why it's done again here\n",
    "#taking the data and standardizing it\n",
    "df = pd.read_csv('training_data/rice_feature_data.csv')\n",
    "feats = ['mean_b', 'var_b', 'skew_b', 'kurt_b', 'entr_b', 'mean_g', 'var_g',\n",
    "       'skew_g', 'kurt_g', 'entr_g', 'mean_r', 'var_r', 'skew_r', 'kurt_r',\n",
    "       'entr_r', 'major_axis_length', 'minor_axis_length', 'area', 'perimeter',\n",
    "       'roundness', 'aspect_ratio']\n",
    "for feat in feats:\n",
    "    df['{}_Z'.format(feat)] = (df[feat] - df[feat].mean()) / df[feat].std()\n",
    "\n",
    "feats_Z = [feat + '_Z' for feat in feats]\n",
    "\n",
    "y = df['class'].values\n",
    "X = df[feats_Z].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938c7efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Best Params: {'n_neighbors': 9}\n",
      "KNN - Accuracy: 0.9800000000000001\n",
      "KNN - Confusion Matrix:\n",
      "[[99  0  1]\n",
      " [ 0 99  1]\n",
      " [ 2  2 96]]\n",
      "KNN - Most frequent hyperparameters: ((('n_neighbors', 1),), 0.9744444444444443) with score 1\n",
      "Random Forest - Best Params: {'max_depth': 2, 'max_features': 3}\n",
      "Random Forest - Accuracy: 0.99\n",
      "Random Forest - Confusion Matrix:\n",
      "[[100   0   0]\n",
      " [  0  99   1]\n",
      " [  1   1  98]]\n",
      "Random Forest - Most frequent hyperparameters: ((('max_depth', 2), ('max_features', 2)), 0.9855555555555554) with score 1\n",
      "MLP - Best Params: {'activation': 'relu', 'hidden_layer_sizes': 19, 'solver': 'adam', 'validation_fraction': 0.5}\n",
      "MLP - Accuracy: 0.9733333333333334\n",
      "MLP - Confusion Matrix:\n",
      "[[100   0   0]\n",
      " [  3  95   2]\n",
      " [  3   0  97]]\n",
      "MLP - Most frequent hyperparameters: ((('activation', 'logistic'), ('hidden_layer_sizes', 3), ('solver', 'sgd'), ('validation_fraction', 0.1)), 0.2733333333333333) with score 1\n"
     ]
    }
   ],
   "source": [
    "# Define models and their respective hyperparameter search ranges\n",
    "models = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=20),\n",
    "    'MLP': MLPClassifier(max_iter=500, early_stopping=True, random_state=20)\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'KNN': {'n_neighbors': range(1, 30)},\n",
    "    'Random Forest': {'max_depth': [2, 4, 6, 8, 10, 12], 'max_features': [2, 3, 4, 5, 6, 7, 8]},\n",
    "    'MLP': {'hidden_layer_sizes': range(3,22),\n",
    "            'activation': ['logistic', 'relu'],\n",
    "            'solver': ['sgd', 'adam'],\n",
    "            'validation_fraction': [0.1,0.5]}\n",
    "}\n",
    "\n",
    "# Perform nested cross-validation for each model\n",
    "outer_kf = KFold(n_splits=10, shuffle=True, random_state=10)\n",
    "inner_kf = RepeatedKFold(n_splits=5, n_repeats=3, random_state=50)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Define parameter grid for this model\n",
    "    param_grid = params[name]\n",
    "\n",
    "    # Perform grid search for best hyperparameters\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=inner_kf)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Use best hyperparameters to evaluate model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    accuracy = cross_val_score(best_model, X=X, y=y, cv=outer_kf, scoring='accuracy')\n",
    "    y_pred = cross_val_predict(best_model, X=X, y=y, cv=outer_kf)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    \n",
    "    # Print results for this model\n",
    "    print(f\"{name} - Best Params: {grid_search.best_params_}\")\n",
    "    print(f\"{name} - Accuracy: {accuracy.mean()}\")\n",
    "    print(f\"{name} - Confusion Matrix:\\n{cm}\")\n",
    "    \n",
    "    # Determine the most frequent hyperparameters for this model\n",
    "    param_results = [(tuple(params.items()), mean_test_score) for params, mean_test_score in zip(grid_search.cv_results_['params'], grid_search.cv_results_['mean_test_score'])]\n",
    "    freq_params = Counter(param_results)\n",
    "    most_freq_params = freq_params.most_common(1)[0]\n",
    "    print(f\"{name} - Most frequent hyperparameters: {most_freq_params[0]} with score {most_freq_params[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fab212",
   "metadata": {},
   "source": [
    "Based on the results(accuracy scores) the Random Forest-model performed the best out of the three with the score of 0.99, KNN followed it closely with accuracy of 0.98, and MLP with accaracy of 0.973. The score with 1 represents how many times to combiantion/parameter was used, but I really didn't understand should it have been used more than once?... maybe I shouldn't have printed with score 1?\n",
    "\n",
    "When considering the limitations and generalization of these models we have to take into account that these models have been trained for a specific dataset which was a really small portion of the orignal dataset. And that's why their performance might not be as good when they would be used for other datasets of the full dataset.\n",
    "\n",
    "Our results are comparable to the article in a sense that the Random Forest model achieved the highest accuracy on both(mine and the article). There were differences in specific hyperparamaters and accuracy scores reportted though.\n",
    "\n",
    "The models could be used in applications that need to classify different speceies of rice or other plants, which can lead to more effecitien crop managment for example. Addition further study in this area should consist maybe of other models.\n",
    "\n",
    "Overall, I learned the process of tuning and evaluating machine learning models, and how difficult it is and that you have to always keep in mind the limitations and generalizations of these models. And for sure I could improve my working progress by researching more and doing more work, just like in many of these data-analysis courses it reads that only way to learn data-analysis is by doing data-analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1746054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "232px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
